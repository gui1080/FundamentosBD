{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTbJkCSE7-Nm"
   },
   "source": [
    "## Universidade de Brasília\n",
    "## Instituto de Ciências Exatas\n",
    "## Departamento de Ciência da Computação - PPCA\n",
    "## Disciplina: Fundamentos de Banco de Dados\n",
    "Projeto de Banco de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8Z9u_8lW778X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importa módulos usados\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import types\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Definindo funções\n",
    "def ler_csv(arquivo, separador, colunas, codificacao, nomes_colunas):\n",
    "    df = pd.read_csv(arquivo, delimiter=separador, usecols=colunas, encoding=codificacao)\n",
    "    df.columns = nomes_colunas\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PjSHkd5PKQNV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "# cwd = os.getcwd()\n",
    "# print(\"Current working directory: {0}\".format(cwd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWM554VWA9oU"
   },
   "source": [
    "## Órgãos do SIAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "RPXo4u_vDn9D",
    "outputId": "fb390a96-b868-49c5-fb7b-c2a015ae7f8f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582 rows\n"
     ]
    }
   ],
   "source": [
    "csv = 'orgaos.CSV'\n",
    "df_orgao = pd.read_csv(csv, encoding='ISO-8859-1')\n",
    "df_orgao.columns = ['cod', 'nome', 'cnpj', 'codpoder', 'nomepoder', 'codtipoadministracao', 'nometipoadministracao']\n",
    "print('{:,}'.format(len(df_orgao)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [0, 1, 2, 3, 4, 5, 7, 9, 10, 14, 15, 16, 17, 18, 19]\n",
    "campos = [ 'idprocessoviagem', 'numproposta', 'situacao', 'viagemurgente', 'justificativaurgencia',\n",
    "           'codorgsuperior', 'codorgpagador', 'cpfviajante', 'nome', 'datainicio', \n",
    "           'datafim', 'destinos', 'motivo', 'valordiarias', 'valorpassagens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,358,260 rows\n"
     ]
    }
   ],
   "source": [
    "# 2023, 2022, 2021, 2020, 2019\n",
    "df_viagem = ler_csv('2023_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df = ler_csv('2022_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_viagem = pd.concat([df_viagem, df])\n",
    "df = ler_csv('2021_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_viagem = pd.concat([df_viagem, df])\n",
    "df = ler_csv('2020_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_viagem = pd.concat([df_viagem, df])\n",
    "df = ler_csv('2019_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_viagem = pd.concat([df_viagem, df])\n",
    "print('{:,}'.format(len(df_viagem)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados de Viagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,358,259 rows\n"
     ]
    }
   ],
   "source": [
    "# Sim e não para boolean\n",
    "df_viagem['viagemurgente'] = df_viagem['viagemurgente'].map({'sim': True, 'não': False})\n",
    "df_viagem['viagemurgente'].astype(bool)\n",
    "# Troca vírgula por ponto no float\n",
    "# Convertendo a coluna valor para float\n",
    "df_viagem['valordiarias'] = df_viagem['valordiarias'].str.replace(',', '.')\n",
    "df_viagem['valordiarias'] = df_viagem['valordiarias'].astype(float)\n",
    "df_viagem['valorpassagens'] = df_viagem['valorpassagens'].str.replace(',', '.')\n",
    "df_viagem['valorpassagens'] = df_viagem['valorpassagens'].astype(float)\n",
    "# Unificando código do ministério do planejamento\n",
    "df_viagem['codorgsuperior'] = df_viagem['codorgsuperior'].replace(47000, 20113)\n",
    "# Par \"cpf\" e \"nome\" representa atributo identificador e não pode estar vazio\n",
    "df_viagem['cpfviajante'].fillna(\"Não informado\", inplace = True)\n",
    "df_viagem['nome'].fillna(\"Não informado\", inplace = True)\n",
    "# Dropando linhas duplicadas\n",
    "df_viagem = df_viagem.drop_duplicates(subset=['idprocessoviagem'])\n",
    "print('{:,}'.format(len(df_viagem)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pessoas\n",
    "\n",
    "Originário da tabela viagem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,358,260 rows\n"
     ]
    }
   ],
   "source": [
    "cols = [ 9, 10, 11, 12, 13]\n",
    "campos = [ 'cpfviajante', 'nome', 'cargo', 'funcao', 'descricaofuncao' ]\n",
    "\n",
    "# 2023, 2022, 2021, 2020, 2019\n",
    "df_passageiros = ler_csv('2023_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df = ler_csv('2022_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_passageiros = pd.concat([df_passageiros, df])\n",
    "df = ler_csv('2021_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_passageiros = pd.concat([df_passageiros, df])\n",
    "df = ler_csv('2020_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_passageiros = pd.concat([df_passageiros, df])\n",
    "df = ler_csv('2019_Viagem.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_passageiros = pd.concat([df_passageiros, df])\n",
    "print('{:,}'.format(len(df_passageiros)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza de dados de Pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418,725 rows\n"
     ]
    }
   ],
   "source": [
    "# Par \"cpf\" e \"nome\" representa atributo identificador e não pode estar vazio\n",
    "df_passageiros['cpfviajante'].fillna(\"Não informado\", inplace = True)\n",
    "df_passageiros['nome'].fillna(\"Não informado\", inplace = True)\n",
    "\n",
    "df_passageiros['cargo'].fillna(\"Desconhecido\", inplace = True)\n",
    "df_passageiros['funcao'].fillna(\"Desconhecido\", inplace = True)\n",
    "df_passageiros['descricaofuncao'].fillna(\"Desconhecido\", inplace = True)\n",
    "\n",
    "# remover duplicatas\n",
    "df_passageiros=df_passageiros.drop_duplicates(subset=['cpfviajante', 'nome'], keep='first')\n",
    "print('{:,}'.format(len(df_passageiros)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trechos de Viagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols =   [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "campos = ['idprocessoviagem', 'seqtrecho', 'dataorigem', 'paisorigem', 'uforigem', 'cidadeorigem',\n",
    "          'datadestino', 'paisdestino', 'ufdestino', 'cidadedestino',\n",
    "          'meiotrasnporte', 'numdiarias', 'missao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,974,823 rows\n"
     ]
    }
   ],
   "source": [
    "# 2023, 2022, 2021, 2020, 2019\n",
    "df_trecho = ler_csv('2023_Trecho.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df = ler_csv('2022_Trecho.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_trecho = pd.concat([df_trecho, df])\n",
    "df = ler_csv('2021_Trecho.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_trecho = pd.concat([df_trecho, df])\n",
    "df = ler_csv('2020_Trecho.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_trecho = pd.concat([df_trecho, df])\n",
    "df = ler_csv('2019_Trecho.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_trecho = pd.concat([df_trecho, df])\n",
    "print('{:,}'.format(len(df_trecho)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando os dados de Trechos de Viagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,974,819 rows\n"
     ]
    }
   ],
   "source": [
    "# Sim e não para boolean\n",
    "df_trecho['missao'] = df_trecho['missao'].map({'sim': True, 'não': False})\n",
    "df_trecho['missao'].astype(bool)\n",
    "# Convertendo a coluna valor para float\n",
    "df_trecho['numdiarias'] = df_trecho['numdiarias'].str.replace(',', '.')\n",
    "df_trecho['numdiarias'] = df_trecho['numdiarias'].astype(float)\n",
    "# Verificando se há alguma linha com idviagem sem pai\n",
    "df_trecho = df_trecho[df_trecho['idprocessoviagem'].isin(df_viagem['idprocessoviagem'])]\n",
    "# Dropando linhas duplicadas\n",
    "df_trecho = df_trecho.drop_duplicates(subset=['idprocessoviagem', 'seqtrecho'])\n",
    "print('{:,}'.format(len(df_trecho)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxXy90f-SQbN"
   },
   "source": [
    "## Pagamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kj-18QNZu3oQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [0, 1, 2, 4, 6, 8, 9]\n",
    "campos = ['idprocessoviagem', 'numproposta', 'codorgsuperior', 'codorgpagador', 'codunidgestorapagadora', 'tipopagamento', 'valor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Huu8uu_CDESt",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,816,631 rows\n"
     ]
    }
   ],
   "source": [
    "# 2023, 2022, 2021, 2020, 2019\n",
    "df_pagamento = ler_csv('2023_Pagamento.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df = ler_csv('2022_Pagamento.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_pagamento = pd.concat([df_pagamento, df])\n",
    "df = ler_csv('2021_Pagamento.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_pagamento = pd.concat([df_pagamento, df])\n",
    "df = ler_csv('2020_Pagamento.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_pagamento = pd.concat([df_pagamento, df])\n",
    "df = ler_csv('2019_Pagamento.csv', ';', cols, 'ISO-8859-1', campos)\n",
    "df_pagamento = pd.concat([df_pagamento, df])\n",
    "print ('{:,}'.format(len(df_pagamento)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDqlzRP2gLvO"
   },
   "source": [
    "### Limpando os dados de Pagamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oMMHXhyHgLWe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,816,631 rows\n"
     ]
    }
   ],
   "source": [
    "# Convertendo a coluna valor para float\n",
    "df_pagamento['valor'] = df_pagamento['valor'].str.replace(',', '.')\n",
    "df_pagamento['valor'] = df_pagamento['valor'].astype(float)\n",
    "# Acertando código de orgão sigiloso\n",
    "df_pagamento.loc[df_pagamento['codorgsuperior'] <= 0, 'codorgsuperior'] = -1\n",
    "df_pagamento.loc[df_pagamento['codorgpagador'] <= 0, 'codorgpagador'] = -1\n",
    "df_pagamento.loc[df_pagamento['codunidgestorapagadora'] <= 0, 'codunidgestorapagadora'] = -1\n",
    "# Unificando código do ministério do planejamento\n",
    "df_pagamento['codorgsuperior'] = df_pagamento['codorgsuperior'].replace(47000, 20113)\n",
    "# Verificando se há alguma linha com idviagem sem pai\n",
    "df_pagamento = df_pagamento[df_pagamento['idprocessoviagem'].isin(df_viagem['idprocessoviagem'])]\n",
    "print ('{:,}'.format(len(df_pagamento)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7tsjI7138Jm",
    "outputId": "b81e5d1b-c150-4d7a-f66c-44d620c712fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor total    : R$ 4.431.837.400,55\n",
      "Valor em sigilo: R$ 826.267.766,15\n"
     ]
    }
   ],
   "source": [
    "soma = df_pagamento['valor'].sum()\n",
    "print('Valor total    : ' + 'R$ {:,.2f}'.format(soma).replace(\",\", \";\").replace(\".\", \",\").replace(\";\", \".\"))\n",
    "soma = df_pagamento.loc[df_pagamento['codunidgestorapagadora'] <= 0, 'valor'].sum()\n",
    "print('Valor em sigilo: ' + 'R$ {:,.2f}'.format(soma).replace(\",\", \";\").replace(\".\", \",\").replace(\";\", \".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DywqcEbpuU-T",
    "tags": []
   },
   "source": [
    "## Conexão com o Banco de dados e Carga dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de carga: 0:13:32.519878\n"
     ]
    }
   ],
   "source": [
    "inicio_transacao = datetime.datetime.now()\n",
    "###########\n",
    "engine = create_engine('postgresql://postgres:postgres@172.22.22.231:5432/fbdprojeto')\n",
    "df_orgao.to_sql('orgao', engine, if_exists='append', index=False)\n",
    "df_passageiros.to_sql('passageiro', engine, if_exists='append', index=False)\n",
    "df_viagem.to_sql('viagem', engine, if_exists='append', index=False)\n",
    "df_pagamento.to_sql('pagamento', engine, if_exists='append', index=False)\n",
    "df_trecho.to_sql('trecho', engine, if_exists='append', index=False)\n",
    "###########\n",
    "fim_transacao = datetime.datetime.now()\n",
    "print('Tempo total de carga: {}'.format(fim_transacao - inicio_transacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
